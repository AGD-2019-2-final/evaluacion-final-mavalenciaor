{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted data.tsv\n",
      "rm: `.': Is a directory\n",
      "Found 2 items\n",
      "-rw-r--r--   1 root supergroup       1780 2020-02-16 16:55 data.tsv\n",
      "-rw-r--r--   1 root supergroup    2271958 2020-02-16 15:48 truck_event_text_partition.csv\n"
     ]
    }
   ],
   "source": [
    "%load_ext bigdata\n",
    "%pig_start\n",
    "%timeout 300\n",
    "!hadoop fs -rm data.tsv .\n",
    "!hadoop fs -put data.tsv .\n",
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " records = LOAD 'data.tsv' AS (c1:CHARARRAY, c2:CHARARRAY, c3:CHARARRAY);\n",
      " DUMP records\n",
      "2020-02-16 16:56:22,883 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:56:23,251 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-02-16 16:56:23,258 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2020-02-16 16:56:23,276 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication\n",
      "2020-02-16 16:56:23,919 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
      "2020-02-16 16:56:23,938 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:56:23,991 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2020-02-16 16:56:24,190 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-16 16:56:24,251 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-16 16:56:24,405 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-16 16:56:24,715 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1581861269524_0064\n",
      "2020-02-16 16:56:25,070 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-02-16 16:56:25,364 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1581861269524_0064\n",
      "2020-02-16 16:56:25,453 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://4882b3231283:8088/proxy/application_1581861269524_0064/\n",
      "2020-02-16 16:56:50,829 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:56:50,867 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:56:51,386 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:56:51,398 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:56:51,460 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-02-16 16:56:51,464 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:56:51,480 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:56:51,638 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:56:51,646 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:56:51,720 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:56:51,729 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:56:51,791 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:56:51,802 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:56:51,913 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(E,{(b),(g),(f)},[jjj#3,bbb#0,ddd#9,ggg#8,hhh#2])\n",
      "(A,{(a),(f),(c)},[ccc#2,ddd#0,aaa#3,hhh#9])\n",
      "(B,{(f),(e),(a),(c)},[ddd#2,ggg#5,ccc#6,jjj#1])\n",
      "(A,{(a),(b)},[hhh#9,iii#5,eee#7,bbb#1])\n",
      "(C,{(f),(g),(d),(a)},[iii#6,ddd#5,eee#4,jjj#3])\n",
      "(A,{(c),(d)},[bbb#2,hhh#0,ccc#4,fff#1,aaa#7])\n",
      "(A,{(g),(d),(a)},[aaa#5,fff#8,ddd#2,iii#0,jjj#7,ccc#1])\n",
      "(B,{(b),(a)},[fff#3,hhh#1,ddd#2])\n",
      "(E,{(d),(e),(a),(f)},[eee#4,ccc#5,iii#9,fff#7,ggg#6,bbb#0])\n",
      "(B,{(d),(b),(g),(f)},[bbb#7,jjj#9,fff#5,iii#4,ggg#2,eee#3])\n",
      "(C,{(d),(c),(f),(b)},[hhh#6,eee#4,iii#0,fff#2,jjj#1])\n",
      "(C,{(d),(e),(a),(c)},[bbb#7,iii#6,ggg#9])\n",
      "(D,{(g),(e),(f),(b)},[bbb#9,aaa#3,ccc#6,fff#4,eee#2])\n",
      "(E,{(c),(f)},[aaa#8,ddd#5,jjj#1])\n",
      "(B,{(d),(b)},[ccc#0,jjj#6,fff#7,ddd#3,aaa#2])\n",
      "(D,{(f),(e)},[ccc#0,eee#6,bbb#9,ddd#3])\n",
      "(E,{(e),(b),(f)},[bbb#6,iii#3,hhh#5,fff#4,ggg#9,ddd#2])\n",
      "(D,{(g),(a)},[hhh#4,jjj#5,ccc#9])\n",
      "(E,{(e),(c),(f),(a)},[ccc#1,iii#6,fff#9])\n",
      "(E,{(e),(a)},[bbb#9,aaa#3,fff#1])\n",
      "(E,{(e),(f)},[ddd#9,iii#2,aaa#4])\n",
      "(E,{(c),(b),(g)},[ccc#5,fff#8,iii#7])\n",
      "(D,{(c),(f),(a)},[eee#3,jjj#2,ddd#7])\n",
      "(A,{(f),(a),(d)},[jjj#1,ggg#0,ccc#7,ddd#9,bbb#3])\n",
      "(E,{(c),(d)},[jjj#6,ccc#0,aaa#1,hhh#9,iii#7,ggg#8])\n",
      "(E,{(e),(d),(c)},[fff#3,eee#6,iii#4,bbb#7,ddd#0,ccc#1])\n",
      "(A,{(a),(e),(f)},[fff#0,ddd#5,ccc#4])\n",
      "(E,{(c),(a),(g)},[ggg#6,hhh#3,ddd#9,ccc#0,jjj#7])\n",
      "(A,{(f),(e)},[hhh#6,jjj#0,eee#5,iii#7,ccc#3])\n",
      "(C,{(f),(c),(a),(g)},[eee#1,fff#4,aaa#2,ccc#7,ggg#0,ddd#6])\n",
      "(A,{(b),(f)},[ccc#6,aaa#9,eee#5,ddd#0,bbb#3])\n",
      "(D,{(b),(f)},[bbb#7,hhh#1,aaa#6,iii#4,fff#9,ddd#5])\n",
      "(E,{(a),(c)},[fff#3,ccc#1,ggg#2,eee#5])\n",
      "(B,{(b),(f),(c)},[iii#7,ggg#3,ddd#0,jjj#8,hhh#5,ccc#1])\n",
      "(B,{(f),(a),(e)},[hhh#6,ccc#3,jjj#0,bbb#8,ddd#7])\n",
      "(D,{(a),(f)},[aaa#0,fff#5,ddd#3])\n",
      "(B,{(c),(a)},[ddd#5,jjj#2,iii#7,ccc#0,bbb#4])\n",
      "(C,{(c),(a),(e),(f)},[eee#0,fff#2,hhh#6])\n",
      "(E,{(e),(d)},[fff#9,iii#2,eee#0])\n",
      "(E,{(f),(a),(d)},[hhh#8,ggg#3,jjj#5])\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "records = LOAD 'data.tsv' AS (c1:CHARARRAY, c2:CHARARRAY, c3:CHARARRAY);\n",
    "DUMP records;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " third_col = FOREACH records GENERATE c3;\n",
      " third_col_b = FOREACH third_col GENERATE REPLACE(c3, '\\\\]', '') AS c3;\n",
      " third_col_c = FOREACH third_col_b GENERATE REPLACE(c3, '\\\\[', '') AS c3;\n",
      " third_col_d = FOREACH third_col_c GENERATE REPLACE(c3, '\\\\#', '') AS c3;\n",
      ";third_col_e = FOREACH third_col_d GENERATE REPLACE(c3, '[0-9]', '') AS c3 \n",
      " DUMP third_col_e;\n",
      "2020-02-16 16:58:52,157 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:58:52,860 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:58:52,898 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-16 16:58:52,923 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-16 16:58:52,984 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-16 16:58:53,047 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1581861269524_0065\n",
      "2020-02-16 16:58:53,054 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-02-16 16:58:53,131 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1581861269524_0065\n",
      "2020-02-16 16:58:53,141 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://4882b3231283:8088/proxy/application_1581861269524_0065/\n",
      "2020-02-16 16:59:33,293 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:59:33,328 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:59:33,461 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:59:33,468 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:59:33,522 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:59:33,529 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:59:33,592 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:59:33,605 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:59:33,706 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:59:33,715 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:59:33,782 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:59:33,790 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:59:33,869 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(jjj,bbb,ddd,ggg,hhh)\n",
      "(ccc,ddd,aaa,hhh)\n",
      "(ddd,ggg,ccc,jjj)\n",
      "(hhh,iii,eee,bbb)\n",
      "(iii,ddd,eee,jjj)\n",
      "(bbb,hhh,ccc,fff,aaa)\n",
      "(aaa,fff,ddd,iii,jjj,ccc)\n",
      "(fff,hhh,ddd)\n",
      "(eee,ccc,iii,fff,ggg,bbb)\n",
      "(bbb,jjj,fff,iii,ggg,eee)\n",
      "(hhh,eee,iii,fff,jjj)\n",
      "(bbb,iii,ggg)\n",
      "(bbb,aaa,ccc,fff,eee)\n",
      "(aaa,ddd,jjj)\n",
      "(ccc,jjj,fff,ddd,aaa)\n",
      "(ccc,eee,bbb,ddd)\n",
      "(bbb,iii,hhh,fff,ggg,ddd)\n",
      "(hhh,jjj,ccc)\n",
      "(ccc,iii,fff)\n",
      "(bbb,aaa,fff)\n",
      "(ddd,iii,aaa)\n",
      "(ccc,fff,iii)\n",
      "(eee,jjj,ddd)\n",
      "(jjj,ggg,ccc,ddd,bbb)\n",
      "(jjj,ccc,aaa,hhh,iii,ggg)\n",
      "(fff,eee,iii,bbb,ddd,ccc)\n",
      "(fff,ddd,ccc)\n",
      "(ggg,hhh,ddd,ccc,jjj)\n",
      "(hhh,jjj,eee,iii,ccc)\n",
      "(eee,fff,aaa,ccc,ggg,ddd)\n",
      "(ccc,aaa,eee,ddd,bbb)\n",
      "(bbb,hhh,aaa,iii,fff,ddd)\n",
      "(fff,ccc,ggg,eee)\n",
      "(iii,ggg,ddd,jjj,hhh,ccc)\n",
      "(hhh,ccc,jjj,bbb,ddd)\n",
      "(aaa,fff,ddd)\n",
      "(ddd,jjj,iii,ccc,bbb)\n",
      "(eee,fff,hhh)\n",
      "(fff,iii,eee)\n",
      "(hhh,ggg,jjj)\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "third_col = FOREACH records GENERATE c3;\n",
    "third_col_b = FOREACH third_col GENERATE REPLACE(c3, '\\\\]', '') AS c3;\n",
    "third_col_c = FOREACH third_col_b GENERATE REPLACE(c3, '\\\\[', '') AS c3;\n",
    "third_col_d = FOREACH third_col_c GENERATE REPLACE(c3, '\\\\#', '') AS c3;\n",
    "third_col_e = FOREACH third_col_d GENERATE REPLACE(c3, '[0-9]', '') AS c3;\n",
    "DUMP third_col_e;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " div = FOREACH third_col_e GENERATE FLATTEN(TOKENIZE(c3)) AS c3;\n",
      " grouped = GROUP div BY c3;\n",
      " letcount = FOREACH grouped GENERATE group, COUNT(div);\n",
      " DUMP letcount;\n",
      "2020-02-16 17:01:05,981 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 17:01:06,717 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 17:01:06,750 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-16 17:01:06,774 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-16 17:01:06,829 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-16 17:01:06,865 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1581861269524_0066\n",
      "2020-02-16 17:01:06,884 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-02-16 17:01:06,952 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1581861269524_0066\n",
      "2020-02-16 17:01:06,956 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://4882b3231283:8088/proxy/application_1581861269524_0066/\n",
      "2020-02-16 17:01:47,605 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 17:01:47,625 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 17:01:47,764 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 17:01:47,772 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 17:01:47,829 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 17:01:47,854 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 17:01:48,001 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 17:01:48,007 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 17:01:48,092 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 17:01:48,103 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 17:01:48,171 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 17:01:48,177 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 17:01:48,267 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(aaa,13)\n",
      "(bbb,16)\n",
      "(ccc,23)\n",
      "(ddd,23)\n",
      "(eee,15)\n",
      "(fff,20)\n",
      "(ggg,13)\n",
      "(hhh,16)\n",
      "(iii,18)\n",
      "(jjj,18)\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "div = FOREACH third_col_e GENERATE FLATTEN(TOKENIZE(c3)) AS c3;\n",
    "grouped = GROUP div BY c3;\n",
    "letcount = FOREACH grouped GENERATE group, COUNT(div);\n",
    "DUMP letcount;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " STORE letcount INTO 'output';\n",
      "2020-02-16 17:03:20,475 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2020-02-16 17:03:20,601 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 17:03:20,832 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 17:03:20,894 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-16 17:03:20,914 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-16 17:03:21,381 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-16 17:03:21,444 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1581861269524_0067\n",
      "2020-02-16 17:03:21,462 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-02-16 17:03:21,551 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1581861269524_0067\n",
      "2020-02-16 17:03:21,559 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://4882b3231283:8088/proxy/application_1581861269524_0067/\n",
      "2020-02-16 17:04:06,696 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 17:04:06,725 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 17:04:06,926 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 17:04:06,936 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 17:04:07,004 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 17:04:07,008 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 17:04:07,085 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 17:04:07,094 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 17:04:07,181 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 17:04:07,189 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 17:04:07,304 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 17:04:07,311 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "STORE letcount INTO 'output';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fs -get output/ .\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "fs -get output/ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted output/_SUCCESS\n",
      "Deleted output/part-r-00000\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -rm output/*\n",
    "!hadoop fs -rmdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pig_quit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
