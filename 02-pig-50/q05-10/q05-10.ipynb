{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bigdata extension is already loaded. To reload it, use:\n",
      "  %reload_ext bigdata\n",
      "rm: `data.tsv': No such file or directory\n",
      "rm: `.': Is a directory\n",
      "Found 2 items\n",
      "-rw-r--r--   1 root supergroup       1780 2020-02-16 16:12 data.tsv\n",
      "-rw-r--r--   1 root supergroup    2271958 2020-02-16 15:48 truck_event_text_partition.csv\n"
     ]
    }
   ],
   "source": [
    "%load_ext bigdata\n",
    "%pig_start\n",
    "%timeout 300\n",
    "!hadoop fs -rm data.tsv .\n",
    "!hadoop fs -put data.tsv .\n",
    "!hadoop fs -ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " records = LOAD 'data.tsv' AS (c1:CHARARRAY, c2:CHARARRAY, c3:CHARARRAY);\n",
      " DUMP records\n",
      "2020-02-16 16:12:53,599 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:12:53,898 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.reduce.markreset.buffer.percent is deprecated. Instead, use mapreduce.reduce.markreset.buffer.percent\n",
      "2020-02-16 16:12:53,908 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.output.compress is deprecated. Instead, use mapreduce.output.fileoutputformat.compress\n",
      "2020-02-16 16:12:53,924 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.submit.replication is deprecated. Instead, use mapreduce.client.submit.file.replication\n",
      "2020-02-16 16:12:54,526 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.job.tracker.http.address is deprecated. Instead, use mapreduce.jobtracker.http.address\n",
      "2020-02-16 16:12:54,538 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:12:54,577 [JobControl] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id\n",
      "2020-02-16 16:12:54,707 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-16 16:12:54,746 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-16 16:12:54,894 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-16 16:12:55,146 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1581861269524_0042\n",
      "2020-02-16 16:12:55,402 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-02-16 16:12:55,590 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1581861269524_0042\n",
      "2020-02-16 16:12:55,634 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://4882b3231283:8088/proxy/application_1581861269524_0042/\n",
      "2020-02-16 16:13:15,871 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:13:15,881 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:13:16,146 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:13:16,161 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:13:16,223 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.reduce.tasks is deprecated. Instead, use mapreduce.job.reduces\n",
      "2020-02-16 16:13:16,226 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:13:16,232 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:13:16,346 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:13:16,355 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:13:16,418 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:13:16,425 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:13:16,490 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:13:16,498 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:13:16,594 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(E,{(b),(g),(f)},[jjj#3,bbb#0,ddd#9,ggg#8,hhh#2])\n",
      "(A,{(a),(f),(c)},[ccc#2,ddd#0,aaa#3,hhh#9])\n",
      "(B,{(f),(e),(a),(c)},[ddd#2,ggg#5,ccc#6,jjj#1])\n",
      "(A,{(a),(b)},[hhh#9,iii#5,eee#7,bbb#1])\n",
      "(C,{(f),(g),(d),(a)},[iii#6,ddd#5,eee#4,jjj#3])\n",
      "(A,{(c),(d)},[bbb#2,hhh#0,ccc#4,fff#1,aaa#7])\n",
      "(A,{(g),(d),(a)},[aaa#5,fff#8,ddd#2,iii#0,jjj#7,ccc#1])\n",
      "(B,{(b),(a)},[fff#3,hhh#1,ddd#2])\n",
      "(E,{(d),(e),(a),(f)},[eee#4,ccc#5,iii#9,fff#7,ggg#6,bbb#0])\n",
      "(B,{(d),(b),(g),(f)},[bbb#7,jjj#9,fff#5,iii#4,ggg#2,eee#3])\n",
      "(C,{(d),(c),(f),(b)},[hhh#6,eee#4,iii#0,fff#2,jjj#1])\n",
      "(C,{(d),(e),(a),(c)},[bbb#7,iii#6,ggg#9])\n",
      "(D,{(g),(e),(f),(b)},[bbb#9,aaa#3,ccc#6,fff#4,eee#2])\n",
      "(E,{(c),(f)},[aaa#8,ddd#5,jjj#1])\n",
      "(B,{(d),(b)},[ccc#0,jjj#6,fff#7,ddd#3,aaa#2])\n",
      "(D,{(f),(e)},[ccc#0,eee#6,bbb#9,ddd#3])\n",
      "(E,{(e),(b),(f)},[bbb#6,iii#3,hhh#5,fff#4,ggg#9,ddd#2])\n",
      "(D,{(g),(a)},[hhh#4,jjj#5,ccc#9])\n",
      "(E,{(e),(c),(f),(a)},[ccc#1,iii#6,fff#9])\n",
      "(E,{(e),(a)},[bbb#9,aaa#3,fff#1])\n",
      "(E,{(e),(f)},[ddd#9,iii#2,aaa#4])\n",
      "(E,{(c),(b),(g)},[ccc#5,fff#8,iii#7])\n",
      "(D,{(c),(f),(a)},[eee#3,jjj#2,ddd#7])\n",
      "(A,{(f),(a),(d)},[jjj#1,ggg#0,ccc#7,ddd#9,bbb#3])\n",
      "(E,{(c),(d)},[jjj#6,ccc#0,aaa#1,hhh#9,iii#7,ggg#8])\n",
      "(E,{(e),(d),(c)},[fff#3,eee#6,iii#4,bbb#7,ddd#0,ccc#1])\n",
      "(A,{(a),(e),(f)},[fff#0,ddd#5,ccc#4])\n",
      "(E,{(c),(a),(g)},[ggg#6,hhh#3,ddd#9,ccc#0,jjj#7])\n",
      "(A,{(f),(e)},[hhh#6,jjj#0,eee#5,iii#7,ccc#3])\n",
      "(C,{(f),(c),(a),(g)},[eee#1,fff#4,aaa#2,ccc#7,ggg#0,ddd#6])\n",
      "(A,{(b),(f)},[ccc#6,aaa#9,eee#5,ddd#0,bbb#3])\n",
      "(D,{(b),(f)},[bbb#7,hhh#1,aaa#6,iii#4,fff#9,ddd#5])\n",
      "(E,{(a),(c)},[fff#3,ccc#1,ggg#2,eee#5])\n",
      "(B,{(b),(f),(c)},[iii#7,ggg#3,ddd#0,jjj#8,hhh#5,ccc#1])\n",
      "(B,{(f),(a),(e)},[hhh#6,ccc#3,jjj#0,bbb#8,ddd#7])\n",
      "(D,{(a),(f)},[aaa#0,fff#5,ddd#3])\n",
      "(B,{(c),(a)},[ddd#5,jjj#2,iii#7,ccc#0,bbb#4])\n",
      "(C,{(c),(a),(e),(f)},[eee#0,fff#2,hhh#6])\n",
      "(E,{(e),(d)},[fff#9,iii#2,eee#0])\n",
      "(E,{(f),(a),(d)},[hhh#8,ggg#3,jjj#5])\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "records = LOAD 'data.tsv' AS (c1:CHARARRAY, c2:CHARARRAY, c3:CHARARRAY);\n",
    "DUMP records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " second_col = FOREACH records GENERATE c2;\n",
      " second_col_b = FOREACH second_col GENERATE REPLACE(c2, '\\\\}', '') AS c2;\n",
      ";second_col_c = FOREACH second_col_b GENERATE REPLACE(c2, '\\\\)', '') AS c2 \n",
      ";second_col_d = FOREACH second_col_c GENERATE REPLACE(c2, '\\\\{', '') AS c2 \n",
      ";second_col_e = FOREACH second_col_d GENERATE REPLACE(c2, '\\\\(', '') AS c2 \n",
      " DUMP second_col_e;\n",
      "2020-02-16 16:40:53,842 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:40:54,773 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:40:54,787 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-16 16:40:54,797 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-16 16:40:54,838 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-16 16:40:54,874 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1581861269524_0057\n",
      "2020-02-16 16:40:54,879 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-02-16 16:40:54,913 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1581861269524_0057\n",
      "2020-02-16 16:40:54,915 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://4882b3231283:8088/proxy/application_1581861269524_0057/\n",
      "2020-02-16 16:41:14,937 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:41:14,950 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:41:14,993 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:41:14,995 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:41:15,018 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:41:15,020 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:41:15,044 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:41:15,046 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:41:15,070 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:41:15,072 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:41:15,094 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:41:15,097 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:41:15,124 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(b,g,f)\n",
      "(a,f,c)\n",
      "(f,e,a,c)\n",
      "(a,b)\n",
      "(f,g,d,a)\n",
      "(c,d)\n",
      "(g,d,a)\n",
      "(b,a)\n",
      "(d,e,a,f)\n",
      "(d,b,g,f)\n",
      "(d,c,f,b)\n",
      "(d,e,a,c)\n",
      "(g,e,f,b)\n",
      "(c,f)\n",
      "(d,b)\n",
      "(f,e)\n",
      "(e,b,f)\n",
      "(g,a)\n",
      "(e,c,f,a)\n",
      "(e,a)\n",
      "(e,f)\n",
      "(c,b,g)\n",
      "(c,f,a)\n",
      "(f,a,d)\n",
      "(c,d)\n",
      "(e,d,c)\n",
      "(a,e,f)\n",
      "(c,a,g)\n",
      "(f,e)\n",
      "(f,c,a,g)\n",
      "(b,f)\n",
      "(b,f)\n",
      "(a,c)\n",
      "(b,f,c)\n",
      "(f,a,e)\n",
      "(a,f)\n",
      "(c,a)\n",
      "(c,a,e,f)\n",
      "(e,d)\n",
      "(f,a,d)\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "second_col = FOREACH records GENERATE c2;\n",
    "second_col_b = FOREACH second_col GENERATE REPLACE(c2, '\\\\}', '') AS c2;\n",
    "second_col_c = FOREACH second_col_b GENERATE REPLACE(c2, '\\\\)', '') AS c2;\n",
    "second_col_d = FOREACH second_col_c GENERATE REPLACE(c2, '\\\\{', '') AS c2;\n",
    "second_col_e = FOREACH second_col_d GENERATE REPLACE(c2, '\\\\(', '') AS c2;\n",
    "DUMP second_col_e;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " div = FOREACH second_col_e GENERATE FLATTEN(TOKENIZE(c2)) AS c2;\n",
      " grouped = GROUP div BY c2;\n",
      " letcount = FOREACH grouped GENERATE group, COUNT(div);\n",
      " DUMP letcount;\n",
      "2020-02-16 16:48:19,917 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:48:20,680 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:48:20,712 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-16 16:48:20,726 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-16 16:48:21,176 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-16 16:48:21,218 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1581861269524_0062\n",
      "2020-02-16 16:48:21,223 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-02-16 16:48:21,293 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1581861269524_0062\n",
      "2020-02-16 16:48:21,299 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://4882b3231283:8088/proxy/application_1581861269524_0062/\n",
      "2020-02-16 16:49:01,735 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:49:01,790 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:49:01,988 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:49:01,995 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:49:02,049 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:49:02,053 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:49:02,107 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:49:02,111 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:49:02,157 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:49:02,161 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:49:02,205 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:49:02,209 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:49:02,263 [main] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "(a,22)\n",
      "(b,12)\n",
      "(c,17)\n",
      "(d,13)\n",
      "(e,15)\n",
      "(f,25)\n",
      "(g,9)\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "div = FOREACH second_col_e GENERATE FLATTEN(TOKENIZE(c2)) AS c2;\n",
    "grouped = GROUP div BY c2;\n",
    "letcount = FOREACH grouped GENERATE group, COUNT(div);\n",
    "DUMP letcount;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " STORE letcount INTO 'output';\n",
      "2020-02-16 16:52:05,340 [main] INFO  org.apache.hadoop.conf.Configuration.deprecation - mapred.textoutputformat.separator is deprecated. Instead, use mapreduce.output.textoutputformat.separator\n",
      "2020-02-16 16:52:05,454 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:52:05,632 [JobControl] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:52:05,659 [JobControl] WARN  org.apache.hadoop.mapreduce.JobResourceUploader - No job jar file set.  User classes may not be found. See Job or Job#setJar(String).\n",
      "2020-02-16 16:52:05,680 [JobControl] INFO  org.apache.hadoop.mapreduce.lib.input.FileInputFormat - Total input files to process : 1\n",
      "2020-02-16 16:52:06,131 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - number of splits:1\n",
      "2020-02-16 16:52:06,191 [JobControl] INFO  org.apache.hadoop.mapreduce.JobSubmitter - Submitting tokens for job: job_1581861269524_0063\n",
      "2020-02-16 16:52:06,199 [JobControl] INFO  org.apache.hadoop.mapred.YARNRunner - Job jar is not present. Not adding any jar to the list of resources.\n",
      "2020-02-16 16:52:06,281 [JobControl] INFO  org.apache.hadoop.yarn.client.api.impl.YarnClientImpl - Submitted application application_1581861269524_0063\n",
      "2020-02-16 16:52:06,296 [JobControl] INFO  org.apache.hadoop.mapreduce.Job - The url to track the job: http://4882b3231283:8088/proxy/application_1581861269524_0063/\n",
      "2020-02-16 16:52:46,696 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:52:46,716 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:52:46,907 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:52:46,918 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:52:46,989 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:52:46,994 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:52:47,060 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:52:47,066 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:52:47,134 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:52:47,139 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n",
      "2020-02-16 16:52:47,205 [main] INFO  org.apache.hadoop.yarn.client.RMProxy - Connecting to ResourceManager at /0.0.0.0:8032\n",
      "2020-02-16 16:52:47,213 [main] INFO  org.apache.hadoop.mapred.ClientServiceDelegate - Application state is completed. FinalApplicationStatus=SUCCEEDED. Redirecting to job history server\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "STORE letcount INTO 'output';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fs -get output/ .\n"
     ]
    }
   ],
   "source": [
    "%%pig\n",
    "fs -get output/ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted output/_SUCCESS\n",
      "Deleted output/part-r-00000\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -rm output/*\n",
    "!hadoop fs -rmdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pig_quit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
